\begin{table}[!t]
\caption{Variations on analogy. 
 Visualized in
\fig{featuretree}.}\label{tbl:aben}

\begin{tabular}{|p{.94\linewidth}|}\hline

\begin{itemize}
\item
To measure    similarity between  $x,y$, 
ABE uses $\sqrt{\sum_{i=1}^n w_i(x_i-y_i)^2}$ where  $w_i$ corresponds to {\em feature} weights applied to independent {\em features}. ABE0 uses a uniform weighting where $w_i=1$.
ABE0's {\em adaptation strategy} is to return the  effort   of the nearest $k=1$   item.
\item
{\em Two ways to find training subsets}:
(a) Remove nothing: Usually, effort estimators use all training projects~\cite{chang1974finding}. Our ABE0 is using this variant;
(b) Outlier methods: prune training projects with (say) suspiciously large  values~\cite{keung2008analogy}. Typically, this removes a small percentage of the training data.
\item
{\em Eight ways to make feature weighting}:
Li {\it et al.}~\cite{li2009study} and Hall and Holmes~\cite{hall2003benchmarking} review 8 different {\em feature} weighting schemes.
\item
{\em Three ways to discretize} (summarize numeric ranges into a few bins):
Some {\em feature} weighting schemes require an initial discretization of continuous  columns. There are many discretization policies in the literature, including:
(1)~equal frequency,
(2)~equal width, 
% (4)PKID~\cite{yang2002comparative},
(3)~do nothing.
\item
{\em Six ways to choose similarity measurements:}
Mendes {\it et al.}~\cite{mendes2003comparative} discuss three similarity measures, including the weighted Euclidean measure described above, an unweighted variant (where $w_i$ = 1), and a ``maximum distance'' measure that focuses on the single {\em feature} that maximizes interproject distance. Frank {\it et al.}~\cite{frank2002locally} use a triangular distribution that sets to the weight to zero after the distance is more than ``k'' neighbors away from the test instance. A fifth and sixth similarity measure are the Minkowski distance measure used in~\cite{angelis2000simulation} and the mean value of the ranking of each project {\em feature} used in~\cite{walkerden1999empirical}.
\item
{\em Four ways for adaption mechanisms:} 
(1)~median effort value,
(2)~mean dependent value,
(3)~summarize the adaptations via a second learner (e.g., linear regression)~\cite{li2009study,menzies2006selecting,baker2007hybrid,quinlan1992learning},
(4)~weighted mean~\cite{mendes2003comparative}.
\item
{\em Six ways to select analogies:}
Analogy selectors  are  fixed or dynamic~\cite{teak2012}. Fixed methods use $k\in\{1,2,3,4,5\}$
nearest neighbors
while  dynamic methods use the training set to find which $1 \le k \le N-1$ is best for   $N$ examples.
\end{itemize}
\\\hline
\end{tabular}
\end{table}